{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8N8_ge9cDg6"
   },
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "For this part of the assignment you implement two different types of generative adversarial networks. We will train the networks on the Celeb A dataset which is a large set of celebrity face images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Zic9S3PaS5g",
    "outputId": "54c84870-24f2-43a0-fa02-123ac4bc3fc5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ANW5IBkFbgJd"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"/CS498DL/assignment4_materials/assignment4_materials/gan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtI7HGfxaAUz",
    "outputId": "e6d7bffe-f8c1-4ddf-f76b-b37a75e1200c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chmod: cannot access '/content/drive/MyDrive/assignment4_materials/download_celeba.sh': No such file or directory\n",
      "/bin/bash: /content/drive/MyDrive/assignment4_materials/download_celeba.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!chmod +x \"/content/drive/MyDrive/assignment4_materials/download_celeba.sh\"\n",
    "!\"/content/drive/MyDrive/assignment4_materials/download_celeba.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRNx4wtGvPYR",
    "outputId": "d8c0a8f2-c77c-4e5c-afc9-5050da6a7f90"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-710Hh-8-nti"
   },
   "outputs": [],
   "source": [
    "from gan.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Bh5rbR7DcDhH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"gpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGpsWMANcDhJ"
   },
   "source": [
    "# GAN loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WhpLQvPcDhK"
   },
   "source": [
    "In this assignment you will implement two different types of GAN cost functions. You will first implement the loss from the [original GAN paper](https://arxiv.org/pdf/1406.2661.pdf). You will also implement the loss from [LS-GAN](https://arxiv.org/abs/1611.04076). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOVWxdbK-nuI"
   },
   "source": [
    "### GAN loss\n",
    "\n",
    "**TODO:** Implement the `discriminator_loss` and `generator_loss` functions in `gan/losses.py`.\n",
    "\n",
    "The generator loss is given by:\n",
    "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "and the discriminator loss is:\n",
    "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "Note that these are negated from the equations presented earlier as we will be *minimizing* these losses.\n",
    "\n",
    "**HINTS**: You should use the `torch.nn.functional.binary_cross_entropy_with_logits` function to compute the binary cross entropy loss since it is more numerically stable than using a softmax followed by BCE loss. The BCE loss is needed to compute the log probability of the true label given the logits output from the discriminator. Given a score $s\\in\\mathbb{R}$ and a label $y\\in\\{0, 1\\}$, the binary cross entropy loss is\n",
    "\n",
    "$$ bce(s, y) = -y * \\log(s) - (1 - y) * \\log(1 - s) $$\n",
    "\n",
    "\n",
    "Instead of computing the expectation of $\\log D(G(z))$, $\\log D(x)$ and $\\log \\left(1-D(G(z))\\right)$, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KQkURZmncDhL"
   },
   "outputs": [],
   "source": [
    "from gan.losses import discriminator_loss, generator_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXfoe96P-nud"
   },
   "source": [
    "### Least Squares GAN loss\n",
    "\n",
    "**TODO:** Implement the `ls_discriminator_loss` and `ls_generator_loss` functions in `gan/losses.py`.\n",
    "\n",
    "We'll now look at [Least Squares GAN](https://arxiv.org/abs/1611.04076), a newer, more stable alernative to the original GAN loss function. For this part, all we have to do is change the loss function and retrain the model. We'll implement equation (9) in the paper, with the generator loss:\n",
    "$$\\ell_G  =  \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[\\left(D(G(z))-1\\right)^2\\right]$$\n",
    "and the discriminator loss:\n",
    "$$ \\ell_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\left(D(x)-1\\right)^2\\right] + \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[ \\left(D(G(z))\\right)^2\\right]$$\n",
    "\n",
    "\n",
    "**HINTS**: Instead of computing the expectation, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing. When plugging in for $D(x)$ and $D(G(z))$ use the direct output from the discriminator (`scores_real` and `scores_fake`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gcbHKxg6cDhO"
   },
   "outputs": [],
   "source": [
    "from gan.losses import ls_discriminator_loss, ls_generator_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D4NN3g1cDhR"
   },
   "source": [
    "# GAN model architecture\n",
    "\n",
    "**TODO:** Implement the `Discriminator` and `Generator` networks in `gan/models.py`.\n",
    "\n",
    "We recommend the following architectures which are inspired by [DCGAN](https://arxiv.org/pdf/1511.06434.pdf):\n",
    "\n",
    "**Discriminator:**\n",
    "\n",
    "- convolutional layer with in_channels=3, out_channels=128, kernel=4, stride=2\n",
    "- convolutional layer with in_channels=128, out_channels=256, kernel=4, stride=2\n",
    "- batch norm\n",
    "- convolutional layer with in_channels=256, out_channels=512, kernel=4, stride=2\n",
    "- batch norm\n",
    "- convolutional layer with in_channels=512, out_channels=1024, kernel=4, stride=2\n",
    "- batch norm\n",
    "- convolutional layer with in_channels=1024, out_channels=1, kernel=4, stride=1\n",
    "\n",
    "Use padding = 1 (not 0) for all the convolutional layers.\n",
    "\n",
    "Instead of Relu we LeakyReLu throughout the discriminator (we use a negative slope value of 0.2). You can use simply use relu as well.\n",
    "\n",
    "The output of your discriminator should be a single value score corresponding to each input sample. See `torch.nn.LeakyReLU`.\n",
    "\n",
    "\n",
    "**Generator:**\n",
    "\n",
    "**Note:** In the generator, you will need to use transposed convolution (sometimes known as fractionally-strided convolution or deconvolution). This function is implemented in pytorch as `torch.nn.ConvTranspose2d`.\n",
    "\n",
    "- transpose convolution with in_channels=NOISE_DIM, out_channels=1024, kernel=4, stride=1\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=1024, out_channels=512, kernel=4, stride=2\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=512, out_channels=256, kernel=4, stride=2\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=256, out_channels=128, kernel=4, stride=2\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=128, out_channels=3, kernel=4, stride=2\n",
    "\n",
    "The output of the final layer of the generator network should have a `tanh` nonlinearity to output values between -1 and 1. The output should be a 3x64x64 tensor for each sample (equal dimensions to the images from the dataset).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2GJ79-qNcDhR"
   },
   "outputs": [],
   "source": [
    "from gan.models import Discriminator, Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sgpDWlbM90t"
   },
   "source": [
    "# Data loading: Celeb A Dataset\n",
    "\n",
    "The CelebA images we provide have been filtered to obtain only images with clear faces and have been cropped and downsampled to 128x128 resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XRDbz7oxcDhU"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "scale_size = 64  # We resize the images to 64x64 for training\n",
    "\n",
    "celeba_root = 'celeba_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "a6IzyDdZM9bp"
   },
   "outputs": [],
   "source": [
    "celeba_train = ImageFolder(root=celeba_root, transform=transforms.Compose([\n",
    "  transforms.Resize(scale_size),\n",
    "  transforms.ToTensor(),\n",
    "]))\n",
    "\n",
    "celeba_loader_train = DataLoader(celeba_train, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1JkDB-wcDhY"
   },
   "source": [
    "### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "id": "uiThPjUSwc3P",
    "outputId": "6f5b14ee-b058-4b37-f966-a79d336d3316",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-123b1b65175a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mceleba_loader_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_images' is not defined"
     ]
    }
   ],
   "source": [
    "imgs = celeba_loader_train.__iter__().next()[0].numpy().squeeze()\n",
    "show_images(imgs, color=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YM-RXjszcDhb"
   },
   "source": [
    "# Training \n",
    "\n",
    "\n",
    "**TODO:** Fill in the training loop in `gan/train.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gV3Ic7e2cDhb"
   },
   "outputs": [],
   "source": [
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 50\n",
    "learning_rate = 0.0002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYq7hQXicDhe"
   },
   "source": [
    "### Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qbcFiz0pI1yF",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator(noise_dim=NOISE_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "eGXt8PTtcDhg",
    "outputId": "fd6b01fd-92cd-4749-c88e-dbabbe1682bc"
   },
   "outputs": [],
   "source": [
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=learning_rate, betas = (0.5, 0.999))\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=learning_rate, betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nVD3zfFnG6e0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 8.00 GiB (GPU 0; 11.17 GiB total capacity; 7.85 GiB already allocated; 2.89 GiB free; 7.91 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-819e4db72d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m train(D, G, D_optimizer, G_optimizer, discriminator_loss, \n\u001b[1;32m      3\u001b[0m           \u001b[0mgenerator_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           train_loader=celeba_loader_train, device=device)\n\u001b[0m",
      "\u001b[0;32m~/CS498DL/assignment4_materials/assignment4_materials/gan/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(D, G, D_solver, G_solver, discriminator_loss, generator_loss, show_every, batch_size, noise_size, num_epochs, train_loader, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mfake_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mreal_dOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0mfake_dOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0md_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dOut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_dOut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS498DL/assignment4_materials/assignment4_materials/gan/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#convlayer3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS498DL/assignment4_materials/assignment4_materials/gan/spectral_normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \"\"\"\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_u_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    927\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    928\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 8.00 GiB (GPU 0; 11.17 GiB total capacity; 7.85 GiB already allocated; 2.89 GiB free; 7.91 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# original gan\n",
    "train(D, G, D_optimizer, G_optimizer, discriminator_loss, \n",
    "          generator_loss, num_epochs=NUM_EPOCHS, show_every=150,\n",
    "          train_loader=celeba_loader_train, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnlOaM3tcDhl"
   },
   "source": [
    "### Train LS-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69X2hCfacDhm"
   },
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator(noise_dim=NOISE_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pmRgmMNcDho"
   },
   "outputs": [],
   "source": [
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=learning_rate, betas = (0.5, 0.999))\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=learning_rate, betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mK21R3OcDhq"
   },
   "outputs": [],
   "source": [
    "# ls-gan\n",
    "train(D, G, D_optimizer, G_optimizer, ls_discriminator_loss, \n",
    "          ls_generator_loss, num_epochs=NUM_EPOCHS, show_every=200,\n",
    "          train_loader=celeba_loader_train, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fj3zhGgScDhs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MP4_P1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
